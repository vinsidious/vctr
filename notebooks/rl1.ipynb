{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import vectorbtpro as vbt\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "from vctr.data.data_loader import get_data\n",
    "from vctr.features.feature_engineering import add_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "\n",
    "class TradingEnvironment(gym.Env):\n",
    "    def __init__(self, data, initial_balance):\n",
    "        self.initial_balance = initial_balance\n",
    "        self.data = data\n",
    "        self.signals = np.zeros((3, len(data)))  # buy, sell, hold signals\n",
    "        self.current_step = 0\n",
    "        self.position = 0  # current position (number of shares)\n",
    "        self.cash = initial_balance\n",
    "\n",
    "        # Define the action space: 0 - buy, 1 - hold, 2 - sell\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        # Define the observation space\n",
    "        self.features = data.drop(['close'], axis=1).columns\n",
    "        num_features = len(self.features) + 2  # Adding 2 for cash and position\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "\n",
    "        prev_portfolio_value = self.cash + self.position * self.data.iloc[self.current_step - 1]['close']\n",
    "\n",
    "        if action == 0:  # buy\n",
    "            self.signals[0, self.current_step] = 1\n",
    "            shares_to_buy = self.cash // self.data.iloc[self.current_step]['close']\n",
    "            self.position += shares_to_buy\n",
    "            self.cash -= shares_to_buy * self.data.iloc[self.current_step]['close']\n",
    "        elif action == 2:  # sell\n",
    "            self.signals[1, self.current_step] = 1\n",
    "            self.cash += self.position * self.data.iloc[self.current_step]['close']\n",
    "            self.position = 0\n",
    "\n",
    "        current_portfolio_value = self.cash + self.position * self.data.iloc[self.current_step]['close']\n",
    "\n",
    "        obs = self._next_observation()\n",
    "        reward = current_portfolio_value - prev_portfolio_value\n",
    "        done = self.current_step >= len(self.data) - 1\n",
    "        truncated = False\n",
    "        info = {}\n",
    "\n",
    "        return obs, reward, done, truncated, info\n",
    "\n",
    "    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None) -> Tuple[np.ndarray, dict]:\n",
    "        self.current_step = 0\n",
    "        self.done = False\n",
    "        self.position = 0\n",
    "        self.cash = self.initial_balance\n",
    "\n",
    "        if seed:\n",
    "            self.seed(seed)\n",
    "\n",
    "        obs = self._next_observation()\n",
    "        return obs, {'options': options}\n",
    "\n",
    "    def _next_observation(self):\n",
    "        obs = np.hstack(\n",
    "            (\n",
    "                self.data.iloc[self.current_step].drop(['close']).values,\n",
    "                [self.cash / self.initial_balance],\n",
    "                [self.position],\n",
    "            )\n",
    "        )\n",
    "        return obs.reshape(1, -1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 2581 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2207       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.64862895 |\n",
      "|    clip_fraction        | 0.0911     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0335    |\n",
      "|    explained_variance   | -12.2      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.27e+03   |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | 0.0189     |\n",
      "|    value_loss           | 2.27e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2099       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 2          |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.89729106 |\n",
      "|    clip_fraction        | 0.0591     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0896    |\n",
      "|    explained_variance   | -0.78      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 363        |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | 0.00177    |\n",
      "|    value_loss           | 3.98e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2040      |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 4         |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5390892 |\n",
      "|    clip_fraction        | 0.0222    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0831   |\n",
      "|    explained_variance   | -0.0947   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.83e+03  |\n",
      "|    n_updates            | 30        |\n",
      "|    policy_gradient_loss | 0.00551   |\n",
      "|    value_loss           | 6.35e+03  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2011        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049330212 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0561     |\n",
      "|    explained_variance   | -0.137      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.75e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | 0.000757    |\n",
      "|    value_loss           | 5.72e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1985       |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 6          |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12099237 |\n",
      "|    clip_fraction        | 0.0167     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0399    |\n",
      "|    explained_variance   | 0.0723     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.31e+03   |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | 0.00408    |\n",
      "|    value_loss           | 3.76e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1979         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058173393 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0378      |\n",
      "|    explained_variance   | 0.267        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 950          |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | 0.000563     |\n",
      "|    value_loss           | 2.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1969         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.731149e-11 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.000808    |\n",
      "|    explained_variance   | -5.09        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.41e+03     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -2.67e-07    |\n",
      "|    value_loss           | 7.36e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1953      |\n",
      "|    iterations           | 9         |\n",
      "|    time_elapsed         | 9         |\n",
      "|    total_timesteps      | 18432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 490.09485 |\n",
      "|    clip_fraction        | 0.404     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0234   |\n",
      "|    explained_variance   | -0.0827   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.21e+03  |\n",
      "|    n_updates            | 80        |\n",
      "|    policy_gradient_loss | 0.0144    |\n",
      "|    value_loss           | 1.01e+04  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 1939     |\n",
      "|    iterations           | 10       |\n",
      "|    time_elapsed         | 10       |\n",
      "|    total_timesteps      | 20480    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.0869  |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 2.9e+03  |\n",
      "|    n_updates            | 90       |\n",
      "|    policy_gradient_loss | 2.55e-10 |\n",
      "|    value_loss           | 8.69e+03 |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load a training dataset\n",
    "data = get_data('FTM', '15m')\n",
    "data = add_features(data)\n",
    "\n",
    "# Set the initial balance\n",
    "initial_balance = 10000\n",
    "\n",
    "# Create the trading environment with the training data\n",
    "train_env = TradingEnvironment(data, initial_balance)\n",
    "train_env = DummyVecEnv([lambda: train_env])\n",
    "\n",
    "# Create the PPO model\n",
    "policy_kwargs = dict(activation_fn=torch.nn.ReLU, net_arch=[64, 64])\n",
    "model = PPO(\"MlpPolicy\", train_env, verbose=1, policy_kwargs=policy_kwargs)\n",
    "\n",
    "# Train the PPO model\n",
    "model.learn(total_timesteps=20000)\n",
    "\n",
    "# Save the trained PPO model\n",
    "model.save(\"ppo_trading_model\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_balance = 100 * 1000\n",
    "\n",
    "\n",
    "def vectorbt_backtest(data, signals):\n",
    "    entries, exits = pd.Series(signals[0]).astype(bool), pd.Series(signals[1]).astype(bool)\n",
    "\n",
    "    portfolio = vbt.Portfolio.from_signals(\n",
    "        data['close'],  # price data\n",
    "        entries,\n",
    "        exits,\n",
    "        init_cash=initial_balance,\n",
    "        fees=0.001,  # 0.1% fees per trade\n",
    "        freq='15t',\n",
    "    )\n",
    "    return portfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a new dataset for testing\n",
    "data = get_data('FTM', '15m')\n",
    "data = add_features(data)\n",
    "\n",
    "# Create a new trading environment with the test data\n",
    "test_env = TradingEnvironment(data, initial_balance)\n",
    "\n",
    "# Load the saved model\n",
    "trained_model = PPO.load('ppo_trading_model')\n",
    "\n",
    "obs = test_env.reset()[0]\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action, _ = trained_model.predict(obs)\n",
    "    obs, reward, done, _, info = test_env.step(action)\n",
    "    obs = np.array(obs).reshape((1, -1))  # reshape obs after each step\n",
    "\n",
    "# Perform backtesting with vectorbt and analyze the performance\n",
    "vectorbt_portfolio = vectorbt_backtest(data, test_env.signals)\n",
    "\n",
    "# Calculate the performance metrics and plot the portfolio value as shown in the previous response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Start                         2022-01-03 00:00:00\n",
       "End                           2023-03-17 11:00:00\n",
       "Period                          432 days 09:30:00\n",
       "Start Value                              100000.0\n",
       "Min Value                             6732.637538\n",
       "Max Value                           136990.812153\n",
       "End Value                            19088.047516\n",
       "Total Return [%]                       -80.911952\n",
       "Benchmark Return [%]                   -80.931806\n",
       "Total Time Exposure [%]                 99.997591\n",
       "Max Gross Exposure [%]                      100.0\n",
       "Max Drawdown [%]                        95.085336\n",
       "Max Drawdown Duration           418 days 09:15:00\n",
       "Total Orders                                    1\n",
       "Total Fees Paid                           99.9001\n",
       "Total Trades                                    1\n",
       "Win Rate [%]                                  NaN\n",
       "Best Trade [%]                                NaN\n",
       "Worst Trade [%]                               NaN\n",
       "Avg Winning Trade [%]                         NaN\n",
       "Avg Losing Trade [%]                          NaN\n",
       "Avg Winning Trade Duration                    NaT\n",
       "Avg Losing Trade Duration                     NaT\n",
       "Profit Factor                                 NaN\n",
       "Expectancy                                    NaN\n",
       "Sharpe Ratio                            -0.342044\n",
       "Calmar Ratio                            -0.786738\n",
       "Omega Ratio                                0.9944\n",
       "Sortino Ratio                           -0.490528\n",
       "dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorbt_portfolio.stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vctr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
