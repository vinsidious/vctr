{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import vectorbtpro as vbt\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from vctr.data.data_loader import get_data\n",
    "from vctr.data.labeling import label_data_extrema_multi\n",
    "from vctr.data.preprocessing import clean_data\n",
    "from vctr.data.timeseries import preprocess_data_for_lstm\n",
    "from vctr.features.feature_engineering import add_features\n",
    "\n",
    "vbt.settings.set_theme('dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('ETH', '5m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the data stationary.\n",
    "data['log_diff'] = np.log(data['close']).diff()\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "data = add_features(data)\n",
    "data = label_data_extrema_multi(data, 0.04, 0.01)\n",
    "\n",
    "num_features = len(data.columns) - 1\n",
    "num_timesteps = 12\n",
    "batch_size = 32\n",
    "\n",
    "# Clean the data.\n",
    "print('Cleaning data...')\n",
    "data = clean_data(data)\n",
    "\n",
    "# Prepare data for LSTM.\n",
    "print('Preparing data for LSTM...')\n",
    "X_train, y_train, X_test, y_test = preprocess_data_for_lstm(\n",
    "    data, [('label', [0, 1, 2])], num_timesteps, batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(y):\n",
    "    print(pd.Series(np.argmax(y, axis=1)).value_counts(normalize=True))\n",
    "\n",
    "get_dist(y_train)\n",
    "get_dist(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (num_timesteps, num_features)\n",
    "\n",
    "# LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(units=64, input_shape=input_shape, return_sequences=True))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(LSTM(units=64, return_sequences=False))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(units=32, activation='relu'))\n",
    "lstm_model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "lstm_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "lstm_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.3,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "# Extract temporal features from LSTM\n",
    "temporal_features_train = lstm_model.predict(X_train)\n",
    "temporal_features_test = lstm_model.predict(X_test)\n",
    "\n",
    "# Assuming 'predictions' contains the output of the model's predict() function\n",
    "temporal_features_train_labels = np.argmax(temporal_features_train, axis=1)\n",
    "temporal_features_test_labels = np.argmax(temporal_features_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(X, actual):\n",
    "#     predictions = lstm_model.predict(X)\n",
    "#     predictions = np.argmax(predictions, axis=1)\n",
    "#     # print(classification_report(actual, predictions))\n",
    "#     # print(confusion_matrix(actual, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_no_split(\n",
    "    data: pd.DataFrame, targets: List[Tuple[str, List[str]]], lookback: int, batch_size: int\n",
    "):\n",
    "    # One-hot encode target(s)\n",
    "    target_cols = [t[0] for t in targets]\n",
    "    target_values = [t[1] for t in targets]\n",
    "    encoder = OneHotEncoder(categories=target_values)\n",
    "    y = encoder.fit_transform(data[target_cols]).toarray()\n",
    "\n",
    "    # Prepare X\n",
    "    num_features = len(data.columns) - len(target_cols)\n",
    "    num_samples = len(data) - lookback\n",
    "    X = np.zeros((num_samples, lookback, num_features))\n",
    "    for i in range(num_samples):\n",
    "        X[i] = data.iloc[i : i + lookback, : -len(target_cols)].values\n",
    "\n",
    "    # Slice y to match X's number of samples\n",
    "    y = y[:X.shape[0]]\n",
    "\n",
    "    # Reshape 3D data to 2D\n",
    "    X_2d = X.reshape(-1, num_features)\n",
    "\n",
    "    # Apply MinMaxScaler to 2D data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_2d = scaler.fit_transform(X_2d)\n",
    "\n",
    "    # Reshape 2D data back to 3D\n",
    "    X = X_2d.reshape(X.shape)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_predict(data):\n",
    "    # Make the data stationary.\n",
    "    data['log_diff'] = np.log(data['close']).diff()\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "    data = add_features(data)\n",
    "    data = label_data_extrema_multi(data, 0.04, 0.01)\n",
    "\n",
    "    num_features = len(data.columns) - 1\n",
    "    num_timesteps = 12\n",
    "    batch_size = 32\n",
    "\n",
    "    # Clean the data.\n",
    "    print('Cleaning data...')\n",
    "    data = clean_data(data)\n",
    "\n",
    "    # Prepare data for LSTM.\n",
    "    print('Preparing data for LSTM...')\n",
    "    return preprocess_no_split(\n",
    "        data, [('label', [0, 1, 2])], num_timesteps, batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = get_data('BTC', '5m')\n",
    "X, actual = get_data_for_predict(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lstm_model.predict(X)\n",
    "predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _actual = np.argmax(actual, axis=1)\n",
    "# pd.Series(_actual).value_counts(normalize=True)\n",
    "# # pd.Series(predictions).value_counts(normalize=True)\n",
    "get_classification_stats(actual, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def get_classification_stats(y_true, y_pred):\n",
    "    # Convert one-hot encoded labels to their class index\n",
    "    y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "    # Calculate the accuracy score\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Generate the classification report\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "    print(\"Classification report:\")\n",
    "    for label, stats in report.items():\n",
    "        print(f\"{label}:\")\n",
    "        for stat, value in stats.items():\n",
    "            print(f\"  {stat}: {value:.2f}\")\n",
    "\n",
    "    return accuracy, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(temporal_features_test_labels).value_counts(normalize=True))\n",
    "get_dist(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vctr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
