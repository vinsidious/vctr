{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml\n",
    "from evalml import AutoMLSearch\n",
    "from evalml.data_checks import ClassImbalanceDataCheck\n",
    "from evalml.pipelines.components.transformers import Oversampler\n",
    "from evalml.utils import infer_feature_types\n",
    "\n",
    "from vctr.data.data_loader import get_data\n",
    "from vctr.data.pre import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import woodwork as ww\n",
    "\n",
    "from vctr.data.labeling import label_data_extrema_multi\n",
    "from vctr.features.feature_engineering import add_features\n",
    "\n",
    "df = get_data('BTC', '5m')\n",
    "\n",
    "df = add_features(df)\n",
    "df = label_data_extrema_multi(df, 0.06, 0.005)\n",
    "\n",
    "X_train, X_test, y_train, y_test = Preprocessor(df, target=['label']).process(\n",
    "    ['train_test_split', 'over_sampling', 'scaling', 'power_transform']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoMLSearch will use mean CV score to rank pipelines.\n",
      "Using default limit of max_batches=3.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "automl = AutoMLSearch(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    problem_type='multiclass',\n",
    "    objective='f1 macro',\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****************************\n",
      "* Beginning pipeline search *\n",
      "*****************************\n",
      "\n",
      "Optimizing for F1 Macro. \n",
      "Greater score is better.\n",
      "\n",
      "Using SequentialEngine to train and score pipelines.\n",
      "Searching up to 3 batches for a total of None pipelines. \n",
      "Allowed model families: \n",
      "\n",
      "Evaluating Baseline Pipeline: Mode Baseline Multiclass Classification Pipeline\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m automl\u001b[39m.\u001b[39;49msearch(interactive_plot\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/vctr/lib/python3.9/site-packages/evalml/automl/automl_search.py:1056\u001b[0m, in \u001b[0;36mAutoMLSearch.search\u001b[0;34m(self, interactive_plot)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress\u001b[39m.\u001b[39mstart_timing()\n\u001b[1;32m   1055\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_baseline_pipelines()\n\u001b[1;32m   1057\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1058\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_keyboard_interrupt():\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/vctr/lib/python3.9/site-packages/evalml/automl/automl_search.py:1296\u001b[0m, in \u001b[0;36mAutoMLSearch._add_baseline_pipelines\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1287\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEvaluating Baseline Pipeline: \u001b[39m\u001b[39m{\u001b[39;00mbaseline\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1288\u001b[0m computation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39msubmit_evaluation_job(\n\u001b[1;32m   1289\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautoml_config,\n\u001b[1;32m   1290\u001b[0m     baseline,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_holdout,\n\u001b[1;32m   1295\u001b[0m )\n\u001b[0;32m-> 1296\u001b[0m evaluation \u001b[39m=\u001b[39m computation\u001b[39m.\u001b[39;49mget_result()\n\u001b[1;32m   1297\u001b[0m data, cached_data, pipeline, job_log \u001b[39m=\u001b[39m (\n\u001b[1;32m   1298\u001b[0m     evaluation\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1299\u001b[0m     evaluation\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcached_data\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1300\u001b[0m     evaluation\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mpipeline\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1301\u001b[0m     evaluation\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mlogger\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1302\u001b[0m )\n\u001b[1;32m   1303\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_evaluation_callback(pipeline, data, cached_data, job_log)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/vctr/lib/python3.9/site-packages/evalml/automl/engine/sequential_engine.py:47\u001b[0m, in \u001b[0;36mSequentialComputation.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_result\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     39\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Gets the computation result. Will block until the computation is finished.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m    Raises:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39m        Computation results.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwork(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/vctr/lib/python3.9/site-packages/evalml/automl/engine/engine_base.py:418\u001b[0m, in \u001b[0;36mevaluate_pipeline\u001b[0;34m(pipeline, automl_config, X, y, logger, X_holdout, y_holdout)\u001b[0m\n\u001b[1;32m    415\u001b[0m X\u001b[39m.\u001b[39mww\u001b[39m.\u001b[39minit(schema\u001b[39m=\u001b[39mautoml_config\u001b[39m.\u001b[39mX_schema)\n\u001b[1;32m    416\u001b[0m y\u001b[39m.\u001b[39mww\u001b[39m.\u001b[39minit(schema\u001b[39m=\u001b[39mautoml_config\u001b[39m.\u001b[39my_schema)\n\u001b[0;32m--> 418\u001b[0m \u001b[39mreturn\u001b[39;00m train_and_score_pipeline(\n\u001b[1;32m    419\u001b[0m     pipeline,\n\u001b[1;32m    420\u001b[0m     automl_config\u001b[39m=\u001b[39;49mautoml_config,\n\u001b[1;32m    421\u001b[0m     full_X_train\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    422\u001b[0m     full_y_train\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    423\u001b[0m     logger\u001b[39m=\u001b[39;49mlogger,\n\u001b[1;32m    424\u001b[0m     X_holdout\u001b[39m=\u001b[39;49mX_holdout,\n\u001b[1;32m    425\u001b[0m     y_holdout\u001b[39m=\u001b[39;49my_holdout,\n\u001b[1;32m    426\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/vctr/lib/python3.9/site-packages/evalml/automl/engine/engine_base.py:292\u001b[0m, in \u001b[0;36mtrain_and_score_pipeline\u001b[0;34m(pipeline, automl_config, full_X_train, full_y_train, logger, X_holdout, y_holdout)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39m# Encode target for classification problems so that we can support float targets. This is okay because we only use split to get the indices to split on\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[39mif\u001b[39;00m is_classification(automl_config\u001b[39m.\u001b[39mproblem_type):\n\u001b[0;32m--> 292\u001b[0m     full_y_train \u001b[39m=\u001b[39m _encode_classification_target(full_y_train)\n\u001b[1;32m    293\u001b[0m     \u001b[39mif\u001b[39;00m use_holdout:\n\u001b[1;32m    294\u001b[0m         y_holdout \u001b[39m=\u001b[39m _encode_classification_target(y_holdout)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/vctr/lib/python3.9/site-packages/evalml/automl/engine/engine_base.py:216\u001b[0m, in \u001b[0;36mtrain_and_score_pipeline.<locals>._encode_classification_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_encode_classification_target\u001b[39m(y):\n\u001b[1;32m    210\u001b[0m     y_mapping \u001b[39m=\u001b[39m {\n\u001b[1;32m    211\u001b[0m         original_target: encoded_target\n\u001b[1;32m    212\u001b[0m         \u001b[39mfor\u001b[39;00m (encoded_target, original_target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\n\u001b[1;32m    213\u001b[0m             y\u001b[39m.\u001b[39mvalue_counts()\u001b[39m.\u001b[39mindex,\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     }\n\u001b[0;32m--> 216\u001b[0m     \u001b[39mreturn\u001b[39;00m ww\u001b[39m.\u001b[39minit_series(y\u001b[39m.\u001b[39;49mmap(y_mapping))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/vctr/lib/python3.9/site-packages/pandas/core/generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5895\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5896\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5897\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5898\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5899\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5900\u001b[0m ):\n\u001b[1;32m   5901\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5902\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "automl.search(interactive_plot=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vctr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
