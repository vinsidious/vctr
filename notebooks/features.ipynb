{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vectorbtpro as vbt\n",
    "\n",
    "from vctr.data.data_loader import get_data, get_data_with_features_and_labels\n",
    "\n",
    "# data = get_data('CRV', '1h', '2022-01-01')\n",
    "\n",
    "# data = get_data_with_features_and_labels('MATIC', '1h', separate=False, label_args=(0.065, 0.005), start='2022-06-01 00:00:00')\n",
    "data1 = get_data_with_features_and_labels(\n",
    "    'CRV', '15m', separate=False, label_args=(0.03, 0.005), start='2022-01-01'\n",
    ")\n",
    "data2 = get_data_with_features_and_labels(\n",
    "    'BTC', '15m', separate=False, label_args=(0.03, 0.005), start='2022-01-01'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "from alpha_vantage.indicators import Indicators\n",
    "import pandas as pd\n",
    "\n",
    "ts = TimeSeries(key='8HHTNOWUT8NO6N6N', output_format='pandas')\n",
    "\n",
    "# Add two new columns to the data frame for the macroeconomic indicators\n",
    "data['indicator_1'] = None\n",
    "data['indicator_2'] = None\n",
    "\n",
    "# Iterate over each row in the data frame\n",
    "for index, row in data.iterrows():\n",
    "    # Retrieve the macroeconomic indicators from Alpha Vantage\n",
    "    indicator_1, meta_data = ts.get_macroeconomic_indicators(symbol='REAL_GDP', interval='60min', outputsize='compact')\n",
    "    indicator_2, meta_data = ts.get_macroeconomic_indicators(symbol='CPI', interval='60min', outputsize='compact')\n",
    "\n",
    "    # Get the current row's date\n",
    "    current_date = row['date']\n",
    "\n",
    "    # Update the corresponding row with the retrieved indicators\n",
    "    data.at[index, 'indicator_1'] = indicator_1[current_date][0]\n",
    "    data.at[index, 'indicator_2'] = indicator_2[current_date][0]\n",
    "\n",
    "# Print the data frame\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def get_interest_rates():\n",
    "    # replace the \"demo\" apikey below with your own key from https://www.alphavantage.co/support/#api-key\n",
    "    url = 'https://www.alphavantage.co/query?function=FEDERAL_FUNDS_RATE&interval=daily&apikey=8HHTNOWUT8NO6N6N'\n",
    "    r = requests.get(url)\n",
    "    return r.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_interest_rates()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vctr.features.feature_engineering import get_economic_indicator\n",
    "\n",
    "\n",
    "gdp = get_economic_indicator('REAL_GDP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def add_interest_rate_column(dataframe, interest_rate_data):\n",
    "    # Convert interest_rate_data to a DataFrame\n",
    "    interest_rate_df = pd.DataFrame(interest_rate_data['data'])\n",
    "\n",
    "    # Convert the 'date' column to datetime type\n",
    "    interest_rate_df['date'] = pd.to_datetime(interest_rate_df['date'])\n",
    "\n",
    "    # Convert the 'value' column to numeric type\n",
    "    interest_rate_df['value'] = pd.to_numeric(interest_rate_df['value'])\n",
    "\n",
    "    # Set the 'date' column as the index and convert to UTC timezone\n",
    "    interest_rate_df.set_index('date', inplace=True)\n",
    "    interest_rate_df.index = interest_rate_df.index.tz_localize('UTC')\n",
    "\n",
    "    # Convert the dataframe's index to UTC timezone if it's tz-naive or has a different timezone\n",
    "    if dataframe.index.tz is None or dataframe.index.tz.zone != 'UTC':\n",
    "        dataframe = dataframe.tz_convert('UTC')\n",
    "\n",
    "    # Determine the desired frequency from the dataframe\n",
    "    frequency = dataframe.index.to_series().diff().mode().iloc[0]\n",
    "\n",
    "    # Drop duplicates before resampling\n",
    "    dataframe = dataframe.loc[~dataframe.index.duplicated(keep='first')]\n",
    "    interest_rate_df = interest_rate_df.loc[~interest_rate_df.index.duplicated(keep='first')]\n",
    "\n",
    "    # Resample and forward fill the interest rate data to match the desired frequency\n",
    "    resampled_interest_rate = interest_rate_df.resample(frequency).last().ffill()\n",
    "\n",
    "    # Merge the dataframes based on the indices\n",
    "    merged_df = dataframe.merge(resampled_interest_rate, how='left', left_index=True, right_index=True)\n",
    "\n",
    "    # Forward fill the remaining NaN values with the last non-NaN value\n",
    "    merged_df['value'] = merged_df['value'].fillna(method='ffill')\n",
    "\n",
    "    # Rename the 'value' column to 'interest_rate'\n",
    "    merged_df.rename(columns={'value': 'interest_rate'}, inplace=True)\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_interest_rate_column(data, get_interest_rates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_rates = get_interest_rates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "\n",
    "def add_hmm_features(df):\n",
    "  # Create an HMM model.\n",
    "  hmm = GaussianHMM(n_components=2, covariance_type='full')\n",
    "\n",
    "  # Train the HMM model on the OHLCV data.\n",
    "  hmm.fit(df[['close']])\n",
    "\n",
    "  # Generate a sequence of hidden states for the future.\n",
    "  hidden_states = hmm.predict(df[['close']])\n",
    "\n",
    "  # Add the hidden states to the dataframe.\n",
    "  df['hmm_hidden'] = hidden_states\n",
    "\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_hmm_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['close'].vbt.overlay_with_heatmap(df['hmm_hidden']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# instantiate the variance threshold selector with the threshold value\n",
    "selector = VarianceThreshold(threshold=0.1)\n",
    "\n",
    "# fit the selector to the data\n",
    "selector.fit(data)\n",
    "\n",
    "# obtain the boolean mask of the selected features\n",
    "buy_mask = selector.get_support()\n",
    "\n",
    "# get the names of the selected features\n",
    "selected_features = [col for col, m in zip(data.columns, buy_mask) if m]\n",
    "print(\"==>> selected_features: \", selected_features)\n",
    "\n",
    "# remove the redundant features from the dataframe\n",
    "X_train = data[selected_features]\n",
    "\n",
    "# X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def get_economic_indicator(indicator):\n",
    "    # replace the \"demo\" apikey below with your own key from https://www.alphavantage.co/support/#api-key\n",
    "    url = f'https://www.alphavantage.co/query?function={indicator}&interval=daily&apikey=8HHTNOWUT8NO6N6N'\n",
    "    r = requests.get(url)\n",
    "    return r.json()['data']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in ['FEDERAL_FUNDS_RATE', 'REAL_GDP', 'CPI', 'INFLATION', 'RETAIL_SALES', 'DURABLES', 'UNEMPLOYMENT', 'TREASURY_YIELD']:\n",
    "    print(get_economic_indicator(ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vctr.utils.workflow import run_workflow\n",
    "from vctr.data import vbt\n",
    "from vctr.features.feature_engineering import add_features\n",
    "from vctr.data.labeling import label_data_extrema_multi\n",
    "from vctr.data.data_loader import get_data, get_data_with_features_and_labels\n",
    "\n",
    "df = get_data_with_features_and_labels(\n",
    "    'ZEC', '1h', separate=False, label_args=(0.065, 0.005), crypto=True\n",
    ")\n",
    "# data2 = get_data_with_features_and_labels(\n",
    "#     'MANA', '1h', separate=False, label_args=(0.0324, 0.0077), start='2023-01-28 00:00:00'\n",
    "# )\n",
    "\n",
    "# data = get_data('ATOM', '1h')\n",
    "# data = add_features(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df.columns))\n",
    "# print(len(data2.columns))\n",
    "\n",
    "# print(list(set(data2.columns) - set(data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Filter highly correlated features (pearson correlation > 0.8)\n",
    "corr = df.corr()\n",
    "\n",
    "correlated_features = set()\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr.iloc[i, j]) > 0.85:\n",
    "            colname = corr.columns[i]\n",
    "            correlated_features.add(colname)\n",
    "\n",
    "# Print the list of correlated features\n",
    "print(list(correlated_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vectorbtpro as vbt\n",
    "from vctr.data.data_loader import get_data, get_data_with_features_and_labels\n",
    "\n",
    "_data = get_data_with_features_and_labels('MATIC', '1h', separate=False, label_args=(0.04, 0.0075), start='2022-01-01 00:00:00', no_cache=True)\n",
    "\n",
    "# Slice the data so that we cut off everything after 03-11\n",
    "# _data = _data.loc[:'2023-03-10 10:00:00']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vctr.data import vbt\n",
    "\n",
    "df = df.copy()['2023':]\n",
    "\n",
    "fig = df.vc.plot(plot_volume=False)\n",
    "bbands = df.vc.run('bbands')\n",
    "rsi = df.vc.run('rsi')\n",
    "sd_bb = vbt.SIGDET.run(bbands.bandwidth, factor=2)\n",
    "# sd_bb.signal.vbt.plot(fig=fig)\n",
    "\n",
    "# Establish masks for plotting\n",
    "sigdet_up = sd_bb.signal == 1\n",
    "sigdet_dn = sd_bb.signal == -1\n",
    "\n",
    "# buy_mask = data.label == 1\n",
    "# buy_mask.vbt.signals.ranges.plot_shapes(plot_close=False, fig=fig, shape_kwargs=dict(fillcolor='green'))\n",
    "# sell_mask = data.label == 2\n",
    "# sell_mask.vbt.signals.ranges.plot_shapes(plot_close=False, fig=fig, shape_kwargs=dict(fillcolor='red'))\n",
    "\n",
    "piv = vbt.PIVOTINFO.run(df.high, df.low, 0.25, 0.15)\n",
    "# Buy?\n",
    "piv_buy_mask = piv.last_value_crossed_below(df.low)\n",
    "piv_buy_mask.vbt.signals.ranges.plot_shapes(\n",
    "    plot_close=False, fig=fig, shape_kwargs=dict(fillcolor='green', opacity=1)\n",
    ")\n",
    "piv_sell_mask = piv.last_value_crossed_above(bbands.upper)\n",
    "\n",
    "piv_sell_mask.vbt.signals.ranges.plot_shapes(\n",
    "    plot_close=False, fig=fig, shape_kwargs=dict(fillcolor='orange', opacity=1)\n",
    ")\n",
    "\n",
    "piv.conf_value_crossed_above(df.close).vbt.signals.ranges.plot_shapes(\n",
    "    plot_close=False, fig=fig, shape_kwargs=dict(fillcolor='red', opacity=1)\n",
    ")\n",
    "\n",
    "# print(piv.modes)\n",
    "# print(piv.pivots)\n",
    "\n",
    "fig.update_layout(width=1200, height=650)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = d2.vc.plot(plot_volume=False, width=1200, height=650)\n",
    "\n",
    "# rsi = d2.vc.run('rsi')\n",
    "# sig = vbt.SIGDET.run(rsi.rsi, factor=4)\n",
    "# up, dn = sig.signal == 1, sig.signal == -1\n",
    "\n",
    "macd = vbt.talib('MACD').run(d2.close, fastperiod=14, slowperiod=32, signalperiod=9)\n",
    "sig2 = vbt.SIGDET.run(macd.macd, factor=4)\n",
    "up2, dn2 = sig2.signal == 1, sig2.signal == -1\n",
    "\n",
    "\n",
    "up2.vbt.signals.ranges.plot_shapes(plot_close=False, fig=fig, shape_kwargs=dict(fillcolor='cyan', opacity=.3))\n",
    "dn2.vbt.signals.ranges.plot_shapes(plot_close=False, fig=fig, shape_kwargs=dict(fillcolor='yellow', opacity=.3))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sigdet_up.vbt.signals.ranges.plot_shapes(\n",
    "    plot_ohlc=df,\n",
    "    width=1200,\n",
    "    height=600,\n",
    "    ohlc_type='candlestick',\n",
    "    shape_kwargs=dict(fillcolor='green', opacity=0.25),\n",
    ")\n",
    "sigdet_dn.vbt.signals.ranges.plot_shapes(\n",
    "    plot_ohlc=df,\n",
    "    width=1200,\n",
    "    height=600,\n",
    "    ohlc_type='candlestick',\n",
    "    shape_kwargs=dict(fillcolor='red', opacity=0.25),\n",
    "    fig=fig,\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vctr.data.data_loader import get_data, get_data_with_features_and_labels\n",
    "\n",
    "df = get_data_with_features_and_labels('MATIC', '1h', separate=False, label_args=(0.04, 0.0075), start='2023-01-01 00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib as ta\n",
    "\n",
    "\n",
    "def add_supertrend(df, atr_period=10, atr_multiplier=2.0, change_atr=True):\n",
    "    hl2 = (df['high'] + df['low']) / 2\n",
    "    atr = (\n",
    "        ta.ATR(df['high'], df['low'], df['close'], timeperiod=atr_period)\n",
    "        if change_atr\n",
    "        else ta.TRANGE(df['high'], df['low'], df['close']).rolling(window=atr_period).mean()\n",
    "    )\n",
    "\n",
    "    up = hl2 - (atr_multiplier * atr)\n",
    "    dn = hl2 + (atr_multiplier * atr)\n",
    "\n",
    "    up1 = up.shift(1).fillna(up)\n",
    "    dn1 = dn.shift(1).fillna(dn)\n",
    "\n",
    "    df['st_up'] = np.where(df['close'].shift(1) > up1, np.maximum(up, up1), up)\n",
    "    df['st_dn'] = np.where(df['close'].shift(1) < dn1, np.minimum(dn, dn1), dn)\n",
    "\n",
    "    df['st_trend'] = np.where(\n",
    "        df['close'] > df['st_dn'].shift(1), 1, np.where(df['close'] < df['st_up'].shift(1), -1, np.nan)\n",
    "    )\n",
    "    df['st_trend'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "    df['st_buy'] = (df['st_trend'] == 1) & (df['st_trend'].shift(1) == -1).astype(int)\n",
    "    df['st_sell'] = (df['st_trend'] == -1) & (df['st_trend'].shift(1) == 1).astype(int)\n",
    "\n",
    "    df.drop(columns=['st_up', 'st_dn', 'st_trend'], inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = df.copy()\n",
    "\n",
    "d2 = add_supertrend(d2, 10, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from plotly.graph_objs import candlestick\n",
    "import vectorbtpro as vbt\n",
    "\n",
    "d2 = df.copy()\n",
    "\n",
    "d2 = add_supertrend(d2, 10, 2)\n",
    "fig = d2.vbt.ohlcv.plot(width=1200, height=650, plot_volume=False)\n",
    "one, two = d2.st_buy == 1, d2.st_sell == 1\n",
    "one.vbt.signals.ranges.plot_shapes(plot_close=False, fig=fig, shape_kwargs=dict(fillcolor='green', opacity=0.7))\n",
    "two.vbt.signals.ranges.plot_shapes(plot_close=False, fig=fig, shape_kwargs=dict(fillcolor='red', opacity=0.7))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# replace the \"demo\" apikey below with your own key from https://www.alphavantage.co/support/#api-key\n",
    "url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=AAPL&apikey=TMP0580D0ZSFILSH'\n",
    "r = requests.get(url)\n",
    "data = r.json()\n",
    "\n",
    "print(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vctr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
